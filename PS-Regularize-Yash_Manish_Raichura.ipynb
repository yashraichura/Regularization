{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yash Manish Raichura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This individual problem set has three aims:\n",
    "\n",
    " learn to find problematic data (multicollinearity) using condition numbers\n",
    "\n",
    " see how Ridge and Lasso regressions are more stable in case of ill-conditioned data\n",
    "\n",
    " learn to manually create design matrices for a survey data set.\n",
    "\n",
    "We return here to the World Value Survey data, a large survey with ∼90k observations and 430\n",
    "variables. Your task is to compile a large number of variables into a design matrix. The process easily\n",
    "leads to multicollinearity which you have to detect using condition numbers.\n",
    "Thereafter we overfit, but as this is a fairly large dataset, we only achieve this by selecting a small\n",
    "subsample of the data. You can see that overfitting is often related to large condition numbers, and may\n",
    "lead to linear regression validation RMSE to be ridiculously large. But Ridge and Lasso can handle the\n",
    "situation much better.\n",
    "\n",
    "When reasonably coded, the code should run fast (∼30s), except the stepwise condition number procedure (∼10min). So you may want to be careful and not run that code too often.\n",
    "Please submit a) your code (notebooks, rmd, whatever) and b) the results in a final output form (html\n",
    "or pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Values Survey\n",
    "\n",
    "World Value Survey (WVS) is a large survey, conducted in many countries simultaneously. It revolves\n",
    "around public opinion about traditions, economy, politics, life and other things. I recommend you to\n",
    "consult the official questionnaire \n",
    "In this task the central question is V23:\n",
    "\n",
    "All things considered, how satisfied are you with your life as a whole these days? with answers ranging between 1 (completely dissatisfied) and 10 (completely satisfied). We are going to model this variables using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from pylab import *\n",
    "import sklearn\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "from numpy import linalg as LA\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore and clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's load data and take a closer look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Browse the WVS documentation and make sure you are familiar with coding of the variable V23. Note: you also have to consult the codebook to understand all the missings and how to remove those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data = pd.read_csv('wvs.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>MN_228S8</th>\n",
       "      <th>MN_229A</th>\n",
       "      <th>MN_230A</th>\n",
       "      <th>MN_233A</th>\n",
       "      <th>MN_237B1</th>\n",
       "      <th>MN_249A1</th>\n",
       "      <th>MN_249A3</th>\n",
       "      <th>I_RELIGBEL</th>\n",
       "      <th>I_NORM1</th>\n",
       "      <th>I_VOICE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_228S8  MN_229A  MN_230A  \\\n",
       "0  12   1   1   1  -2   1   1    2    1    1  ...         3       -3       -3   \n",
       "1  12   1   2   3   4   2   2    2    2    2  ...         3       -3       -3   \n",
       "2  12   1   3   2   4   2   1    2    2    2  ...         4        1        1   \n",
       "3  12   1   1   3   4   3   1    2    1    2  ...         2        2        1   \n",
       "4  12   1   1   1   2   1   1    1    3    2  ...         2        2        1   \n",
       "\n",
       "   MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  I_VOICE1  \n",
       "0       -3        -3         1         1         0.0      1.0      0.00  \n",
       "1       -3        -3         2        -1         0.0      1.0      0.66  \n",
       "2        2        -3         1         1         0.0      1.0      0.33  \n",
       "3        2        -3         1         2         0.0      1.0      0.00  \n",
       "4        2        -3         1         2         0.0      1.0      0.66  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90350, 328)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V2               0\n",
       "V4               0\n",
       "V5               0\n",
       "V6               0\n",
       "V7               0\n",
       "              ... \n",
       "MN_249A1         0\n",
       "MN_249A3         0\n",
       "I_RELIGBEL    4636\n",
       "I_NORM1       1711\n",
       "I_VOICE1      4445\n",
       "Length: 328, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for NA values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80744, 328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping NA values\n",
    "data.dropna(inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the data. Remove all the missing observations of V23. I mean all the missings, including the valid numeric codes that denote missing/invalid answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing negative values from V23\n",
    "data = data[data.V23 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     16577\n",
       "7     14033\n",
       "10    10714\n",
       "5      9971\n",
       "6      9577\n",
       "9      8491\n",
       "4      4124\n",
       "3      2969\n",
       "1      2280\n",
       "2      1706\n",
       "Name: V23, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out unique values\n",
    "data.V23.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5,  4,  7,  6,  3, 10,  1,  9,  2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique satisfaction levels\n",
    "data.V23.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Now make a table (or a plot) of different answers. What is the mean satisfaction level on this planet? How large a proportion of people are at 6 or more satisfied? (Note: without knowing more about how the sample was created, we should not talk about the planet. We should refer to respondents instead.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.872255786778052"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean satisfaction level\n",
    "data.V23.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean satisfaction level on this planet is 6.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>16577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  count\n",
       "0                   1   2280\n",
       "1                   2   1706\n",
       "2                   3   2969\n",
       "3                   4   4124\n",
       "4                   5   9971\n",
       "5                   6   9577\n",
       "6                   7  14033\n",
       "7                   8  16577\n",
       "8                   9   8491\n",
       "9                  10  10714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of count of people for each satisfaction level\n",
    "table_satisfaction = data.V23.value_counts().to_frame().reset_index()\n",
    "table_satisfaction.rename(columns = {'index': 'satisfaction_level', 'V23':'count'}, inplace = True)\n",
    "table_satisfaction = table_satisfaction.sort_values(by = 'satisfaction_level').reset_index().drop(columns = 'index')\n",
    "table_satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.count of satisfaction_level       55\n",
       "count                 80442\n",
       "dtype: int64>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_satisfaction.sum().count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.count of satisfaction_level       40\n",
       "count                 59392\n",
       "dtype: int64>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_satisfaction[table_satisfaction.satisfaction_level >=  6 ].sum().count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.83207777031899"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proportion greater than or equal to 6\n",
    "\n",
    "59392/80442*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x291718dee88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot for count of people for each satisfaction level\n",
    "table_satisfaction.plot(kind = 'bar', x = 'satisfaction_level', y = 'count', rot = 360, alpha = 0.7, figsize = (12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Design Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to make the data suitable for a regression model. So far we have either used R-style formulas,\n",
    "or fed data into a ML model directly without much preparatory work. Now it is time to construct the\n",
    "design matrix manually. In case of linear regression, the design matrix is the data matrix that will be\n",
    "directly fed into the formula (X|· X)−1X|y, or any function that uses this or another similar formula.\n",
    "Design matrix can also be fed directly into other kind of models, such as logistic regression or decision\n",
    "tree. Design matrix is also needed by various libraries, in particular sklearn's LinearRegression, Ridge,\n",
    "and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many variables are categorical. For instance, variable V2, country, is numeric with different numbers\n",
    "representing different countries. So in essence it is a categorical variable where categories are coded\n",
    "as numbers. The same is true for V80, most serious problem in the world. You should convert such\n",
    "variables to dummies (do your still remember pd.get_dummies?) and remove the original variable.\n",
    "But don't forget to remove missings!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large number of variables contain ordered values instead. For instance, V55 asks how much choice\n",
    "do you feel do you have over your life. The answers range from 1 (no choice at all) to 10 (a great\n",
    "deal of choice). We treat these as numeric response. Although, strictly speaking not correct, the\n",
    "model would be too messy if we were creating a category for each response. However, the missings\n",
    "(-5: inapplicable, -4: not asked etc) are not ordered in any meaningful sense. Hence your task is to\n",
    "remove missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many variables, e.g. v74b (important to help people nearby) and v90 (signing petition), contain\n",
    "a very large number of missings, and hence you essentially lose all your data if you include such variables.\n",
    "So you should remove such variables and replace with others that have more valid answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming V2 column to country\n",
    "data.rename(columns = {'V2' : 'country'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the dataframe\n",
    "X = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a design matrix that contains at least 100 variables from the WVS data. Your selected variables should contain at least a few categorical ones, such as V2 country. In each case:\n",
    "#### (a) remove missing observations\n",
    "#### (b) convert categorical variable to dummies if appropriate. Don't forget to drop the reference category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>number_of_non_zero_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>country</td>\n",
       "      <td>80442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>V62</td>\n",
       "      <td>80442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>V199</td>\n",
       "      <td>80442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>V147</td>\n",
       "      <td>80442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>V23</td>\n",
       "      <td>80442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>V22</td>\n",
       "      <td>80440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>V13</td>\n",
       "      <td>80437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>V14</td>\n",
       "      <td>80437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>V18</td>\n",
       "      <td>80437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>V43</td>\n",
       "      <td>80436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column_name  number_of_non_zero_values\n",
       "0       country                      80442\n",
       "61          V62                      80442\n",
       "222        V199                      80442\n",
       "160        V147                      80442\n",
       "20          V23                      80442\n",
       "19          V22                      80440\n",
       "10          V13                      80437\n",
       "11          V14                      80437\n",
       "15          V18                      80437\n",
       "40          V43                      80436"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding out columns with the least negative values and printing the column values with the number of non negative values in a\n",
    "#dataframe\n",
    "l1 = []\n",
    "l2 = []\n",
    "for i in X.columns:\n",
    "    l1.append(i)\n",
    "    l2.append(len(X[i][X[i] > 0]))\n",
    "df1 = {'column_name' : l1 , 'number_of_non_zero_values' : l2}\n",
    "df1 = pd.DataFrame(df1)\n",
    "df1.sort_values(by = 'number_of_non_zero_values', ascending = False, inplace = True)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the top 100 columns with the least non negative values and putting them in X\n",
    "X = X[df1.head(100).column_name.to_list()]\n",
    "X = X.reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataframe X with the values for the respective columns\n",
    "for i in X.columns:\n",
    "    X = X.loc[X[i] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>V62</th>\n",
       "      <th>V199</th>\n",
       "      <th>V147</th>\n",
       "      <th>V23</th>\n",
       "      <th>V22</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V18</th>\n",
       "      <th>V43</th>\n",
       "      <th>...</th>\n",
       "      <th>V40</th>\n",
       "      <th>V36</th>\n",
       "      <th>V38</th>\n",
       "      <th>V52</th>\n",
       "      <th>V110</th>\n",
       "      <th>V75</th>\n",
       "      <th>V133</th>\n",
       "      <th>V24</th>\n",
       "      <th>V70</th>\n",
       "      <th>V108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  V62  V199  V147  V23  V22  V13  V14  V18  V43  ...  V40  V36  \\\n",
       "1        12    2     4     1    5    2    1    2    2    2  ...    2    1   \n",
       "2        12    1     5     1    4    2    2    2    2    1  ...    2    1   \n",
       "3        12    3     6     1    8    2    2    2    2    1  ...    2    1   \n",
       "4        12    2     5     1    8    2    1    2    1    1  ...    2    1   \n",
       "6        12    2     7     1    7    2    1    2    2    1  ...    2    1   \n",
       "8        12    1     7     1    6    2    2    2    2    2  ...    2    1   \n",
       "10       12    3     4     1    5    2    2    2    2    1  ...    2    1   \n",
       "11       12    2     6     1    3    2    2    1    2    2  ...    2    2   \n",
       "12       12    3     5     1    5    2    2    1    1    2  ...    2    1   \n",
       "13       12    3     5     1    3    2    2    2    2    2  ...    2    1   \n",
       "\n",
       "    V38  V52  V110  V75  V133  V24  V70  V108  \n",
       "1     2    2     1    3     8    1    2     1  \n",
       "2     2    1     2    1     4    1    1     3  \n",
       "3     2    2     4    1     9    2    1     2  \n",
       "4     1    3     3    4     4    2    2     2  \n",
       "6     2    1     4    1     4    2    1     2  \n",
       "8     2    1     4    1     5    2    1     4  \n",
       "10    2    1     3    1     7    1    2     3  \n",
       "11    1    2     3    4     6    2    2     2  \n",
       "12    2    3     2    1     8    2    1     1  \n",
       "13    2    2     2    2     5    1    2     1  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out a few rows of X\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53374, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out rows and columns of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables for the columns V2(country) and V80\n",
    "X = pd.get_dummies(data=X, columns=['country', 'V80'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53374, 155)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out rows and columns of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your outcome variable y out of life satisfaction V23 (remove missings!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.V23\n",
    "X = X.drop(columns = 'V23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condition numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to compute the condition number of your design matrix. It will quite likely be way too\n",
    "big: some of the answers may be highly correlated, you may forget to drop the reference category, the\n",
    "reference category you drop may have no observations, there may be several variables that contain exactly\n",
    "the same information... But we want to know which variables are the culprits. So instead of computing\n",
    "just a single κ, let's add columns to the design matrix one-by-one, and each time printing the column we\n",
    "added, and the resulting condition number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition Numbers: \n",
      "V62 1 columns 1.0\n",
      "V199 2 columns 2.5696655811546845\n",
      "V147 3 columns 6.018316786222353\n",
      "V22 4 columns 8.177085131340787\n",
      "V13 5 columns 9.354500140555752\n",
      "V14 6 columns 10.435482793941837\n",
      "V18 7 columns 11.1435052321177\n",
      "V43 8 columns 12.068451399489557\n",
      "V41 9 columns 16.103800049042352\n",
      "V16 10 columns 16.538618006478746\n",
      "V12 11 columns 17.077034666587934\n",
      "V17 12 columns 17.720960055062836\n",
      "V20 13 columns 18.366965613781126\n",
      "V37 14 columns 22.804667060461107\n",
      "V15 15 columns 23.611802796679452\n",
      "V39 16 columns 24.541776506227592\n",
      "V44 17 columns 25.420672080712297\n",
      "V19 18 columns 26.015909980863665\n",
      "V21 19 columns 26.61143096854149\n",
      "V240 20 columns 27.139376691656445\n",
      "V242 21 columns 156.98122888445337\n",
      "V57 22 columns 157.19368836110382\n",
      "V200 23 columns 157.30099688427794\n",
      "V11 24 columns 157.46339831826168\n",
      "V4 25 columns 157.50505556290136\n",
      "V59 26 columns 158.77222006592729\n",
      "V64 27 columns 158.90243216924023\n",
      "V209 28 columns 159.1971628021183\n",
      "V210 29 columns 159.3294059849332\n",
      "V208 30 columns 159.48238288918444\n",
      "V5 31 columns 159.59200572540738\n",
      "V202 32 columns 159.71754251205004\n",
      "V10 33 columns 159.84264335196494\n",
      "Y002 34 columns 159.9579285581912\n",
      "V63 35 columns 160.17830296586513\n",
      "V60 36 columns 160.27882625700948\n",
      "V84 37 columns 160.51065245947777\n",
      "V6 38 columns 160.6323397138223\n",
      "V188 39 columns 161.0575695365079\n",
      "V248 40 columns 162.17768464220634\n",
      "V211 41 columns 162.25705379401705\n",
      "V55 42 columns 164.07727466686342\n",
      "V225 43 columns 164.22714199430817\n",
      "V198 44 columns 164.47978570199555\n",
      "V9 45 columns 164.62908848904706\n",
      "V102 46 columns 164.6885917211924\n",
      "V191 47 columns 165.02036391622585\n",
      "V179 48 columns 165.77550091276865\n",
      "V190 49 columns 166.185822573215\n",
      "V82 50 columns 166.30815406303088\n",
      "V143 51 columns 166.4279578575627\n",
      "V140 52 columns 168.84906165654186\n",
      "V7 53 columns 169.07597743454497\n",
      "V189 54 columns 169.4896212534499\n",
      "V45 55 columns 169.72123136595397\n",
      "V111 56 columns 169.93001639670837\n",
      "V8 57 columns 170.00765463032693\n",
      "V177 58 columns 170.32090560761958\n",
      "V104 59 columns 170.4655001976603\n",
      "V152 60 columns 172.61174357315096\n",
      "V79 61 columns 172.8453468016903\n",
      "V113 62 columns 173.03695801341962\n",
      "V205 63 columns 173.6931492655651\n",
      "V103 64 columns 173.84498091405067\n",
      "V100 65 columns 174.41918981480606\n",
      "V214 66 columns 174.49827715947376\n",
      "V197 67 columns 176.28258535539928\n",
      "V207 68 columns 176.47063910184428\n",
      "V98 69 columns 177.17796245024235\n",
      "V229 70 columns 177.5474043441549\n",
      "V72 71 columns 177.72723577579674\n",
      "V170 72 columns 177.84057852537734\n",
      "V192 73 columns 179.77017282358855\n",
      "V176 74 columns 180.01606315295396\n",
      "V78 75 columns 180.2280287199447\n",
      "V77 76 columns 180.4347020169275\n",
      "V139 77 columns 182.52368723806998\n",
      "V65 78 columns 182.77142585392195\n",
      "V193 79 columns 184.7649749736049\n",
      "V204 80 columns 185.09626765687833\n",
      "V250 81 columns 185.20257467726924\n",
      "V73 82 columns 185.5360540310589\n",
      "V238 83 columns 185.88975204557124\n",
      "V56 84 columns 186.96258290960859\n",
      "V71 85 columns 187.41667566300336\n",
      "V96 86 columns 188.37357003909796\n",
      "V42 87 columns 188.50302108890577\n",
      "V40 88 columns 189.00023686959494\n",
      "V36 89 columns 189.6349133214661\n",
      "V38 90 columns 190.1687442746776\n",
      "V52 91 columns 190.45077747168625\n",
      "V110 92 columns 190.66277527879467\n",
      "V75 93 columns 190.93448099309725\n",
      "V133 94 columns 192.98074718172066\n",
      "V24 95 columns 193.07939990134454\n",
      "V70 96 columns 193.3185076586477\n",
      "V108 97 columns 193.4894154030158\n",
      "country_31 98 columns 455.2785465450802\n",
      "country_36 99 columns 463.3840175302761\n",
      "country_48 100 columns 612.6891398786005\n",
      "country_51 101 columns 612.6907036037438\n",
      "country_76 102 columns 612.7128791041829\n",
      "country_112 103 columns 612.7312456494647\n",
      "country_152 104 columns 613.09392870461\n",
      "country_156 105 columns 613.235373080478\n",
      "country_158 106 columns 613.236373371951\n",
      "country_170 107 columns 613.3161809941508\n",
      "country_196 108 columns 613.7574491034976\n",
      "country_218 109 columns 614.1778528549155\n",
      "country_233 110 columns 614.2733335249552\n",
      "country_268 111 columns 614.3213469563655\n",
      "country_275 112 columns 614.976886964147\n",
      "country_276 113 columns 616.8967770051919\n",
      "country_288 114 columns 617.1136379811411\n",
      "country_356 115 columns 617.7445610935375\n",
      "country_368 116 columns 618.7575864970432\n",
      "country_398 117 columns 619.2884344356512\n",
      "country_400 118 columns 621.7015929830446\n",
      "country_410 119 columns 624.8014373730404\n",
      "country_417 120 columns 628.8332617747161\n",
      "country_422 121 columns 637.4310964284164\n",
      "country_434 122 columns 645.5557491250925\n",
      "country_458 123 columns 652.492422987493\n",
      "country_484 124 columns 658.732296810097\n",
      "country_504 125 columns 680.7192356610989\n",
      "country_528 126 columns 686.2354406875561\n",
      "country_566 127 columns 691.9362094793582\n",
      "country_586 128 columns 702.154140771543\n",
      "country_604 129 columns 716.2718768742347\n",
      "country_608 130 columns 730.1792146901321\n",
      "country_616 131 columns 744.747782138635\n",
      "country_634 132 columns 767.2005889082144\n",
      "country_642 133 columns 789.9725110784578\n",
      "country_643 134 columns 805.2888447578257\n",
      "country_646 135 columns 819.7634254066434\n",
      "country_702 136 columns 849.4010260631878\n",
      "country_705 137 columns 868.1000434874849\n",
      "country_710 138 columns 926.486518850655\n",
      "country_716 139 columns 992.7904928260091\n",
      "country_724 140 columns 1020.3503339101771\n",
      "country_752 141 columns 1059.8832916651238\n",
      "country_764 142 columns 1116.873296072496\n",
      "country_780 143 columns 1182.8636922152805\n",
      "country_788 144 columns 1248.3446893269397\n",
      "country_792 145 columns 1370.2999459354676\n",
      "country_804 146 columns 1552.4580475286555\n",
      "country_840 147 columns 2098.3128131720414\n",
      "country_858 148 columns 2405.4958313159746\n",
      "country_860 149 columns 3177.5402062513554\n",
      "country_887 150 columns 4103.707095526313\n",
      "V80_2 151 columns 4104.374965049267\n",
      "V80_3 152 columns 4104.882643560735\n",
      "V80_4 153 columns 4104.891794547405\n",
      "V80_5 154 columns 4104.921671570704\n"
     ]
    }
   ],
   "source": [
    "#Calculating the condition number, starting from the first column and appending each column through the last column\n",
    "df = pd.DataFrame()\n",
    "print('Condition Numbers: ')\n",
    "for i in X.columns:\n",
    "    df[i] = X[i]\n",
    "    k = np.linalg.cond(df)\n",
    "    print(i , len(df.columns),'columns', k)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Do Some Social Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting further, let's do a simple social science analysis. How is life satisfaction related to health\n",
    "(v11 ), perceived control over life (v55 ) and financial situation (v59 )? Let's analyze association between\n",
    "satisfaction and just these three variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V23</th>\n",
       "      <th>V11</th>\n",
       "      <th>V55</th>\n",
       "      <th>V59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>V23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2747</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>0.460208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     V23     V11       V55       V59\n",
       "V23  1.0 -0.2747  0.358468  0.460208"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating correlation between the 4 required variables\n",
    "corr_df = data[['V23', 'V11', 'V55', 'V59']]\n",
    "corr_df = corr_df.corr().iloc[0].to_frame().T\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. run a linear regression models explaining satisfaction with these three variables. Present the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    V23   R-squared:                       0.294\n",
      "Model:                            OLS   Adj. R-squared:                  0.294\n",
      "Method:                 Least Squares   F-statistic:                 1.116e+04\n",
      "Date:                Fri, 06 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        16:41:18   Log-Likelihood:            -1.6511e+05\n",
      "No. Observations:               80442   AIC:                         3.302e+05\n",
      "Df Residuals:                   80438   BIC:                         3.303e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.1701      0.032    128.866      0.000       4.107       4.234\n",
      "V11           -0.4062      0.008    -51.383      0.000      -0.422      -0.391\n",
      "V55            0.2259      0.003     75.283      0.000       0.220       0.232\n",
      "V59            0.3294      0.003    115.992      0.000       0.324       0.335\n",
      "==============================================================================\n",
      "Omnibus:                     3261.143   Durbin-Watson:                   1.689\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5281.289\n",
      "Skew:                          -0.362   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.026   Cond. No.                         48.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lm_Data = data[['V23','V11','V55','V59']]\n",
    "lm_model = smf.ols(formula='V23 ~ V11 + V55 + V59', data=lm_Data).fit()\n",
    "print(lm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. comment the output table in terms of relative effect size and statistical significance. Any surprises for you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative_effect_size:  \n",
      "0.4164305949008499\n"
     ]
    }
   ],
   "source": [
    "relative_effect_size = 0.294 / (1  - 0.294)\n",
    "print('relative_effect_size:  ')\n",
    "print(relative_effect_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the correlation table, there is a negative correlation between V23 and V11 and a stronger correlation of V59 with V23 compared to V55. The linear model does decipher this relationship which is depicted with the coefficients of each of these variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. compute and present RMSE (just on training data). This will serve as the benchmark for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_lm = data[['V11','V55','V59']]\n",
    "y_lm = data[['V23']]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_lm,y_lm,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LinearRegression as lm\n",
    "lm_model_train = lm().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.88176837],\n",
       "       [8.66436183],\n",
       "       [6.76864739],\n",
       "       ...,\n",
       "       [7.58008667],\n",
       "       [5.6257673 ],\n",
       "       [8.03215259]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "predictions = lm_model_train.predict(X_train)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8804808855019592"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_train, predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train RMSE is 1.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Back to ML: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to use all these variables to model satisfaction. Use sklearn.linear_model.LinearRegression\n",
    "here as this is easy to be switched with ridge and lasso, and it takes in the design matrix directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the condition number for your design matrix (just a single number, not the stepwise procedure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104.921671570704"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the condition number for the design matrix\n",
    "np.linalg.cond(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting y to a dataframe since it was a series\n",
    "y = y.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Split the data into training-validation chunks (80-20 or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the condition number for your training design matrix (just a single number, not the stepwise procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4157.653314155036"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the condition number for the train design matrix\n",
    "np.linalg.cond(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit a linear regression model where you describe satisfaction with the design matrix X you just created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the linear model\n",
    "lm_model_train = lm().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. predict and compute RMSE on training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.05802689],\n",
       "       [6.28613213],\n",
       "       [8.0201497 ],\n",
       "       ...,\n",
       "       [5.31553822],\n",
       "       [7.9251524 ],\n",
       "       [7.6885177 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting values for y_train\n",
    "predictions = lm_model_train.predict(X_train)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.687696805971712"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating RMSE for train dataset\n",
    "rmse = sqrt(mean_squared_error(y_train, predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Predict and compute RMSE on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.55488428],\n",
       "       [6.06865303],\n",
       "       [7.12704207],\n",
       "       ...,\n",
       "       [5.11516676],\n",
       "       [4.24873903],\n",
       "       [7.02509167]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting values for y_test\n",
    "predictions = lm_model_train.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6648184866365812"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating RMSE for test dataset\n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Repeat the previous with Ridge regression, play a little with different α-s. Which α gave you the best testing RMSE? (No need for a rigorous analysis, just play a little)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.01,0.01,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE value for alpha =  for ridge regression is 0.01 is  1.6648170358048433\n",
      "The test RMSE value for alpha =  for ridge regression is 0.01 is  1.6648170358048433\n",
      "The test RMSE value for alpha =  for ridge regression is 1 is  1.6647145870011186\n",
      "The test RMSE value for alpha =  for ridge regression is 10 is  1.6646608513107544\n",
      "The test RMSE value for alpha =  for ridge regression is 100 is  1.6654164184937383\n",
      "The test RMSE value for alpha =  for ridge regression is 1000 is  1.6759989223549052\n"
     ]
    }
   ],
   "source": [
    "for i in alpha:\n",
    "    rr = Ridge(alpha = i)\n",
    "    ridge = rr.fit(X_train, y_train)\n",
    "    predictions = ridge.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "    print('The test RMSE value for alpha =  for ridge regression is',i, 'is ', rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.  Repeat with Lasso regression again playing a little with different α-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE value for alpha = for lasso regression is 0.01 is  1.6922421016024198\n",
      "The test RMSE value for alpha = for lasso regression is 0.01 is  1.6922421016024198\n",
      "The test RMSE value for alpha = for lasso regression is 1 is  1.9505974216193782\n",
      "The test RMSE value for alpha = for lasso regression is 10 is  2.2128614278132974\n",
      "The test RMSE value for alpha = for lasso regression is 100 is  2.2128614278132974\n",
      "The test RMSE value for alpha = for lasso regression is 1000 is  2.2128614278132974\n"
     ]
    }
   ],
   "source": [
    "for i in alpha:\n",
    "    lasso = Lasso(alpha=i)\n",
    "    Lasso_model = lasso.fit(X_train, y_train)\n",
    "    predictions =lasso.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "    print('The test RMSE value for alpha = for lasso regression is',i, 'is ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. comment your results:\n",
    "#### (a) compare RMSE on testing/training data. What does this suggest in terms of overfitting?\n",
    "#### (b) compare RMSE for OLS, Ridge and Lasso\n",
    "#### (c) compare the resulting RMSE with the small benchmark model you did above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) The RMSE value for training data is 1.68 and the RMSE value for test data is 1.67\n",
    "The RMSE values do not differ much, and the test RMSE follows the Train RMSE closely, which suggests that the model is neither underfitting nor over fitting\n",
    "\n",
    "(b) RMSE for OLS: 1.6954, RMSE for Ridge is 1.689 and RMSE for lasso is 2.19\n",
    "We see that we get similar RMSE values for OLS and Ridge regression models, whereas the RMSE is a bit higher for lasso regression. In ridge regression, the model tries to decrease the coefficients, whereas in lasso, the model makes the coeffiecients of the model 0, and hence for higher values of alpha, the test rmse increase. Here, alpha corresponds to the linear dependancy.\n",
    "For lasso regression, as alpha value increases, the test rmse also increases since it reduces the coefficients of the predictor variables and hence rmse for ridge is comparatively higher for higher values of alpha than ols or ridge. Whereas for lower values of alpha, ridge and lasso behave like linear models only.\n",
    "\n",
    "(c) The RMSE value for our benchmark model is 1.86. Hence, it proves that by adding the regularization parameter (alpha), the RMSE value has reduced from 1.86 to 1.69 for the ridge model, as it introduces a small amount of bias to decrease the variance, and hence there is a decrease in the RMSE  value for test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Let's Overfit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As WVS is a relatively large dataset we cannot easily overfit by adding more variables. But we can go\n",
    "another easy route instead: we take a subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a subsample of your design matrix and the outcome variable. Choose a large-ish sample that overfits. The size depends on which variables do you exactly choose, in my case 2000 obs rarely overfits (it depends on the train-validation split), 1000 typically overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_overfit = X[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 154)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_overfit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_overfit = y[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_overfit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Repeat the steps you did above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_overfit,y_overfit,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number for X_train  1.0515487240697494e+131\n",
      "RMSE for train dataset 1.7791928160467982\n"
     ]
    }
   ],
   "source": [
    "#Fitting the linear model\n",
    "lm_model_train = lm().fit(X_train,y_train)\n",
    "#Predicting values for y_train\n",
    "predictions = lm_model_train.predict(X_train)\n",
    "rmse = sqrt(mean_squared_error(y_train, predictions))\n",
    "c = np.linalg.cond(X_train)\n",
    "print('Condition number for X_train ', c)\n",
    "print('RMSE for train dataset', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number for X_train  1.0515487240697494e+131\n",
      "RMSE for test dataset 2.0438664580025234\n"
     ]
    }
   ],
   "source": [
    "#Fitting the linear model\n",
    "lm_model_train = lm().fit(X_train,y_train)\n",
    "#Predicting values for y_test\n",
    "predictions = lm_model_train.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "c = np.linalg.cond(X_train)\n",
    "rmse\n",
    "print('Condition number for X_train ', c)\n",
    "print('RMSE for test dataset', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE value for alpha =  for ridge regression is 0.01 is  2.043857106545165\n",
      "The test RMSE value for alpha =  for ridge regression is 0.01 is  2.043857106545165\n",
      "The test RMSE value for alpha =  for ridge regression is 1 is  2.0429496961531366\n",
      "The test RMSE value for alpha =  for ridge regression is 10 is  2.036045651238214\n",
      "The test RMSE value for alpha =  for ridge regression is 100 is  2.0086501016700886\n",
      "The test RMSE value for alpha =  for ridge regression is 1000 is  1.9715882413952146\n"
     ]
    }
   ],
   "source": [
    "for i in alpha:\n",
    "    rr = Ridge(alpha = i)\n",
    "    ridge = rr.fit(X_train, y_train)\n",
    "    predictions = ridge.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "    print('The test RMSE value for alpha =  for ridge regression is',i, 'is ', rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE value for alpha = for lasso regression is 0.01 is  2.016724324088806\n",
      "The test RMSE value for alpha = for lasso regression is 0.01 is  2.016724324088806\n",
      "The test RMSE value for alpha = for lasso regression is 1 is  2.110957613777602\n",
      "The test RMSE value for alpha = for lasso regression is 10 is  2.3388031127053\n",
      "The test RMSE value for alpha = for lasso regression is 100 is  2.3388031127053\n",
      "The test RMSE value for alpha = for lasso regression is 1000 is  2.3388031127053\n"
     ]
    }
   ],
   "source": [
    "for i in alpha:\n",
    "    lasso = Lasso(alpha=i)\n",
    "    Lasso_model = lasso.fit(X_train, y_train)\n",
    "    predictions =lasso.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "    print('The test RMSE value for alpha = for lasso regression is',i, 'is ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. comment how do OLS, Ridge, Lasso perform on testing/training in case of overfitting.\n",
    "#### 4. comment the condition number of design matrix and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that train MSE for 1000 observations is 1.75 wheres the test MSE for linear regression is 2.11 which is higher than 1.68 which we got in the previous case where the entire design matrix was used. \n",
    "Since only a sample of the design matrix is used, the condition number is a lot higher - 4.078594937341657e+131 which denotes very little linear dependance within the predictors and the response.\n",
    "This is clearly depicted by the test RMSE which is higher than train MSE and the test MSE in previous cases.\n",
    "\n",
    "For ridge and lasso regression, for low values of alpha, it behaves similar to linear regression but as alpha increases, ridge regression reduces the values of the coefficients of the predictor variables which makes the model fit better in this case since there is not a lot of linear dependance whereas in lasso regression, it makes the coefficient of the predictors 0, which removes the dependance of the response on input variables. In such a case, where there are only 1000 observations and the predictors also reduces, the model performs poorly and hence test RMSE increases for lasso as alpha increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
